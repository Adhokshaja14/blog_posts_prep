---
title: "Data Science for Business - Time Series Forcasting Part 3: Forecasting with prophet"
author: "Dr. Shirin Glander"
date: "`r Sys.Date()`"
output: html_document
---

In my last two posts ([Part 1](https://shiring.github.io/forecasting/2017/05/28/retail_forcasting_part1) and [Part 2](https://shiring.github.io/forecasting/2017/06/09/retail_forcasting_part2)), I explored time series forecasting with the **timekit** package.

In this post, I want to compare how [Facebook's prophet](https://facebookincubator.github.io/prophet/) performs on the same dataset.

<br>

**Timekit** uses a time series signature for modeling, which we used as features to build our model of choice (e.g. a linear model) that we then used for predicting future dates.



The second reason is that often we want to make predictions into the future. There’s a number of packages such as forecast and prophet that already specialize in this. For forecast the future dates can be incorrect especially for daily data. A regular numeric system doesn’t contain true dates and a sequential system results in inaccuracy with respect to irregular dates. For prophet, the mechanism to compute holidays and missing days is internal to the predict() method, and therefore the a method specific to creating future dates is needed. Two types of days cause problems: those that are regularly skipped and irregularly skipped. The regularly skipped days (such as weekends or sometimes companies get to take every other Friday off) need to be factored into the future date sequence. The irregularly skipped days (think holidays) cause issues as well, and these suffer the additional problem as they can be difficult (but not impossible) to predict.

Prophet is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers.

Prophet is open source software released by Facebook's Core Data Science team.

Prophet is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers.
Prophet is open source software released by Facebook’s Core Data Science team. It is available for download on CRAN and PyPI.
Accurate and fast.
Prophet is used in many applications across Facebook for producing reliable forecasts for planning and goal setting. We’ve found it to perform better than any other approach in the majority of cases. We fit models in Stan so that you get forecasts in just a few seconds.
Fully automatic.
Get a reasonable forecast on messy data with no manual effort. Prophet is robust to outliers, missing data, and dramatic changes in your time series.
Tunable forecasts.
The Prophet procedure includes many possibilities for users to tweak and adjust forecasts. You can use human-interpretable parameters to improve your forecast by adding your domain knowledge.
Available in R or Python.
We’ve implemented the Prophet procedure in R and Python, but they share the same underlying Stan code for fitting. Use whatever language you’re comfortable with to get forecasts.

Facebook is a famously data-driven organization, and an important goal in any data science activity is forecasting. Now, Facebook has released Prophet, an open-source package for R and Python that implements the time-series methodology that Facebook uses in production for forecasting at scale.

Prophet has a very simple interface: you pass it a column of dates and a column of numbers, and is produces a forecast for the time series, like this:

The black dots are the number of views of Peyton Manning's Wikipedia page through the end of 2016; the blue region is a forecast (with uncertainty interval) into 2017. As you can see, the Prophet forecast automatically detects the seasonal cycles (presumably related to NFL seasons). The prophet function also provides options to explicitly model weekly and/or yearly seasonality, account for holidays, and to specify changepoints where discontinuities in the time series are expected. It also supports modeling logistic growth, where each data point is measured against a maximum possible capacity.

The underlying model behing the forecast is described in this paper. It's not your traditional ARIMA-style time series model. It's closer in spirit to a Bayesian-influenced generalized additive model, a regression of smooth terms. The model is resistant to the effects of outliers, and supports data collected over an irregular time scale (ingliding presence of missing data) without the need for interpolation. The underlying calculation engine is Stan; the R and Python packages simply provide a convenient interface.

Prophet is billed as a platform for "forecasting at scale", but here "scale" does not refer to data size or computational speed (as we are accustomed to in this domain). As authors Sean Taylor and Ben Letham write in the aforementioned paper:

The actual problems of scale we have observed in practice involve the complexity introduced by the variety of forecasting problems and building trust in a large number of forecasts once they have been produced.

With its simple interface that automates much of the process of finding a "best fit" characterization of a complex time series, Prophet scales easily to a large number of users who need many forecasts of qualitatively many different kinds of data, without in-depth expertise in time series modeling techniques. 

You can find out more about Prophet, including how to install it for R and Python, at the link below.

Today Facebook is open sourcing Prophet, a forecasting tool available in Python and R. Forecasting is a data science task that is central to many activities within an organization. For instance, large organizations like Facebook must engage in capacity planning to efficiently allocate scarce resources and goal setting in order to measure performance relative to a baseline. Producing high quality forecasts is not an easy problem for either machines or for most analysts. We have observed two main themes in the practice of creating a variety of business forecasts:

Completely automatic forecasting techniques can be brittle and they are often too inflexible to incorporate useful assumptions or heuristics.
Analysts who can produce high quality forecasts are quite rare because forecasting is a specialized data science skill requiring substantial experience.
The result of these themes is that the demand for high quality forecasts often far outstrips the pace at which analysts can produce them. This observation is the motivation for our work building Prophet: we want to make it easier for experts and non-experts to make high quality forecasts that keep up with demand.

The typical considerations that “scale” implies, computation and storage, aren’t as much of a concern for forecasting. We have found the computational and infrastructure problems of forecasting a large number of time series to be relatively straightforward — typically these fitting procedures parallelize quite easily and forecasts are not difficult to store in relational databases such as MySQL or data warehouses such as Hive.

The problems of scale we have observed in practice involve the complexity introduced by the variety of forecasting problems and building trust in a large number of forecasts once they have been produced. Prophet has been a key piece to improving Facebook’s ability to create a large number of trustworthy forecasts used for decision-making and even in product features.

Where Prophet shines
Not all forecasting problems can be solved by the same procedure. Prophet is optimized for the business forecast tasks we have encountered at Facebook, which typically have any of the following characteristics:

hourly, daily, or weekly observations with at least a few months (preferably a year) of history
strong multiple “human-scale” seasonalities: day of week and time of year
important holidays that occur at irregular intervals that are known in advance (e.g. the Super Bowl)
a reasonable number of missing observations or large outliers
historical trend changes, for instance due to product launches or logging changes
trends that are non-linear growth curves, where a trend hits a natural limit or saturates
We have found Prophet’s default settings to produce forecasts that are often accurate as those produced by skilled forecasters, with much less effort. With Prophet, you are not stuck with the results of a completely automatic procedure if the forecast is not satisfactory — an analyst with no training in time series methods can improve or tweak forecasts using a variety of easily-interpretable parameters. We have found that by combining automatic forecasting with analyst-in-the-loop forecasts for special cases, it is possible to cover a wide variety of business use-cases. The following diagram illustrates the forecasting process we have found to work at scale:

For the modeling phase of the forecasting process, there are currently only a limited number of tools available. Rob Hyndman’s excellent forecast package in R is probably the most popular option, and Google and Twitter have both released packages with more specific time series functionality — CausalImpact and AnomalyDetection, respectively. As far as we can tell, there are few open source software packages for forecasting in Python.

We have frequently used Prophet as a replacement for the forecast package in many settings because of two main advantages:

Prophet makes it much more straightforward to create a reasonable, accurate forecast. The forecast package includes many different forecasting techniques (ARIMA, exponential smoothing, etc), each with their own strengths, weaknesses, and tuning parameters. We have found that choosing the wrong model or parameters can often yield poor results, and it is unlikely that even experienced analysts can choose the correct model and parameters efficiently given this array of choices.
Prophet forecasts are customizable in ways that are intuitive to non-experts. There are smoothing parameters for seasonality that allow you to adjust how closely to fit historical cycles, as well as smoothing parameters for trends that allow you to adjust how aggressively to follow historical trend changes. For growth curves, you can manually specify “capacities” or the upper limit of the growth curve, allowing you to inject your own prior information about how your forecast will grow (or decline). Finally, you can specify irregular holidays to model like the dates of the Super Bowl, Thanksgiving and Black Friday.
How Prophet works
At its core, the Prophet procedure is an additive regression model with four main components:

A piecewise linear or logistic growth curve trend. Prophet automatically detects changes in trends by selecting changepoints from the data.
A yearly seasonal component modeled using Fourier series.
A weekly seasonal component using dummy variables.
A user-provided list of important holidays.
As an example, here is a characteristic forecast: log-scale page views of Peyton Manning’s Wikipedia page that we downloaded using the wikipediatrend package. Since Peyton Manning is an American football player, you can see that yearly seasonality plays and important role, while weekly periodicity is also clearly present. Finally you see certain events (like playoff games he appears in) may also be modeled.

This plot more clearly shows the yearly seasonality associated with browsing to Peyton Manning’s page (football season and the playoffs), as well as the weekly seasonality: more visits on the day of and after games (Sundays and Mondays). You can also notice the downward adjustment to the trend component since he has retired recently.

The important idea in Prophet is that by doing a better job of fitting the trend component very flexibly, we more accurately model seasonality and the result is a more accurate forecast. We prefer to use a very flexible regression model (somewhat like curve-fitting) instead of a traditional time series model for this task because it gives us more modeling flexibility, makes it easier to fit the model, and handles missing data or outliers more gracefully.

By default, Prophet will provide uncertainty intervals for the trend component by simulating future trend changes to your time series. If you wish to model uncertainty about future seasonality or holiday effects, you can run a few hundred HMC iterations (which takes a few minutes) and your forecasts will include seasonal uncertainty estimates.

We fit the Prophet model using Stan, and have implemented the core of the Prophet procedure in Stan’s probabilistic programming language. Stan performs the MAP optimization for parameters extremely quickly (<1 second), gives us the option to estimate parameter uncertainty using the Hamiltonian Monte Carlo algorithm, and allows us to re-use the fitting procedure across multiple interface languages. Currently we provide implementations of Prophet in both Python and R. They have exactly the same features and by providing both implementations we hope to make our forecasting approach more broadly useful in the data science communities.

How to use Prophet
The simplest way to use Prophet is to install the package from PyPI (Python) or CRAN (R). You can read our quick start guide and dive into our comprehensive documentation. If you’re looking for a fun source of time series data, we recommend trying the wikipediatrend package which will download historical page views on Wikipedia pages.

Help us improve Prophet
There are two main ways to help us improve Prophet. First, you can try it yourself and tell us about your results. We’re always looking for more use cases in order to understand when Prophet performs well and when it does not. Second, there are plenty of features that are left to build! We welcome pull requests with bugfixes and new features. Check out how to contribute, we look forward to engaging with the community to make Prophet even more broadly useful.

I ran across an R forecasting package recently, prophet, I hadn't seen before. This isn't surprising given the flood of new libraries now emerging in the R ecosystem.
Developed by two Facebook data scientists, what struck me most about prophet was the alignment of its sweet spot problem domain with consulting work I'd done a few years ago in digital marketing for a large media company. With that engagement, the challenge was forecasting hundreds of daily time series, each with several years of historical data. Patterns manifested included trend and multiple seasons. Predictions were desired over an entire year, and models were to be updated weekly with the latest data.
I started the work with a pretty standard bag of statistical forecasting tricks, including moving averages, seasonal and trend decomposition, exponential smoothing such as Holt Winters, ARIMA, and even a few econometric alternatives. Alas, after none of these attempts even closely nailed it, I turned to traditional regression and more modern machine learning approaches though, given autocorrelation of disturbances, these are generally considered anathma for forecasting by statistical purists. I was getting desparate, however. A statistical consolation was that I was just interested in the quality of predictions, not overall model purity.
So when I read that: "Prophet is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers.", I just had to test it out. Could this be what I needed years ago?
A data set I'd used to prep for the digital media engagement was daily births in Quebec from 1977-1991. quebec represents counts of 14 years of daily newborn deliveries in the Canadian province. It served nicely for simulating my digital marketing challenges and I figured it could now help me put prophet through its paces as well.
The remainder of this post examines the results of several modeling exercises in R against the quebec data divided into train with 13 years and test with one. prophet is compared against a basic linear model (lm), a general additive model (gam), and random forests (randomForest).
At the start, set a few options, load some libraries, and change the working directory.

```{r warning=FALSE, message=FALSE}
library(prophet)

library(tidyverse)
library(tidyquant)
```

```{r echo=FALSE}
load("retail_p_day.RData")
```

```{r}
retail_p_day <- retail_p_day %>%
  mutate(model = ifelse(day <= "2011-11-01", "train", "test"))

train <- filter(retail_p_day, model == "train") %>%
  select(day, sum_income) %>%
  rename(ds = day,
         y = sum_income)

test <- filter(retail_p_day, model == "test") %>%
  select(day, sum_income) %>%
  rename(ds = day)
```

```{r}
prophet_model_test <- prophet(train, 
                              growth = "linear",
                              n.changepoints = 100,
                              yearly.seasonality = FALSE,
                              weekly.seasonality = TRUE)
```

```{r}
forecast_test <- predict(prophet_model_test, test)
```

```{r message=FALSE, fig.width=8, fig.height=3}
forecast_test %>%
  mutate(resid = sum_income - yhat) %>%
  ggplot(aes(x = ds, y = resid)) +
    geom_hline(yintercept = 0, color = "red") +
    geom_point(alpha = 0.5, color = palette_light()[[1]]) +
    geom_smooth() +
    theme_tq()
```


```{r warning=FALSE, fig.width=8, fig.height=3}
forecast_test %>%
  gather(x, y, sum_income, yhat) %>%
  ggplot(aes(x = ds, y = y, color = x)) +
    geom_point(alpha = 0.5) +
    geom_line(alpha = 0.5) +
    scale_color_manual(values = palette_light()) +
    theme_tq()
```

<br>

```{r}
off_days <- data.frame(ds = as.Date(c("2010-12-24", "2010-12-25", "2010-12-26", "2010-12-27", "2010-12-28", 
                                      "2010-12-29", "2010-12-30", "2010-01-01", "2010-01-02", "2010-01-03",
                                      "2011-04-22", "2011-04-23", "2011-04-24", "2011-04-25", "2011-05-02", 
                                      "2011-05-30", "2011-08-29", "2011-04-29", "2011-04-30"))) %>%
  mutate(holiday = paste0("off_day_", seq_along(1:length(ds))))
```

```{r}
retail_p_day_forecast <- retail_p_day %>%
  select(day, sum_income) %>%
  rename(ds = day,
         y = sum_income)
```

```{r}
prophet_model_future <- prophet(retail_p_day_forecast,
                                growth = "linear",
                                n.changepoints = 100,
                                yearly.seasonality = FALSE,
                                weekly.seasonality = TRUE,
                                holidays = off_days)
```

```{r}
future <- make_future_dataframe(prophet_model_future, periods = 300)
```

```{r}
forecast <- predict(prophet_model_future, future)
```

```{r fig.width=8, fig.height=3}
plot(prophet_model_future, forecast) +
    theme_tq()
```

```{r fig.width=8, fig.height=6}
prophet_plot_components(prophet_model_future, forecast)
```

```{r}
retail_p_day_fill <- data.frame(ds = seq(from = as.Date(min(retail_p_day$day)), to = as.Date(max(retail_p_day$day)), by = "days"))

retail_p_day_forecast_fill <- left_join(retail_p_day_fill, retail_p_day_forecast, by = "ds")
retail_p_day_forecast_fill[is.na(retail_p_day_forecast_fill)] <- 0
```

```{r}
prophet_model_future_fill <- prophet(retail_p_day_forecast_fill, 
                              growth = "linear",
                              n.changepoints = 100,
                              yearly.seasonality = FALSE,
                              weekly.seasonality = TRUE,
                              holidays = off_days)
```

```{r}
forecast_fill <- predict(prophet_model_future_fill, future)
```

```{r fig.width=8, fig.height=3}
plot(prophet_model_future_fill, forecast_fill) +
    theme_tq()
```
